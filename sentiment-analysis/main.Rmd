---
title: "Sentiment Analysis Project"
author: "Asad Sheikh"
date: "6/8/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Sentiment Analysis Project from https://data-flair.training/blogs/data-science-r-sentiment-analysis-project/

```{r}
library(janeaustenr)
library(tidytext)
library(stringr)
library(tidyverse)
library(tidyr)
library(ggplot2)
```


```{r}
sentiments
get_sentiments("bing")
```

Performing Sentiment Analysis with the Inner Join

We will convert the text of our books into a tidy format using unnest_tokens() function.
```{r}
data = austen_books() %>%
  group_by(book) %>%
  mutate(line_number = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)

```

Now, we have created a nice data frame where each word is on a single row. Now, using the "bing" lexicon, we will filter out words that correspond to joy.

```{r}
positive_sentiments = get_sentiments("bing") %>%
  filter(sentiment == "positive")

data %>%
  filter(book == "Emma") %>%
  semi_join(positive_sentiments) %>%
  count(word, sort = TRUE)
```

Now, we will sepearate the data into columns of positive and negative sentiments, and then calculate the total sentiment.

```{r}
bing = get_sentiments("bing")
emma_sentiment = data %>%
  inner_join(bing) %>%
  count(book = "Emma", index = line_number %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
```

Visualizing overall scores

```{r}
ggplot(emma_sentiment, aes(index, sentiment, fill = book)) +
  geom_bar(stat = "identity", show.legend = TRUE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

Counting most common positive and negative words
```{r}
counting_words = data %>%
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE)
head(counting_words)
```

Visualizing sentiment score

```{r}
counting_words %>%
  filter(n > 150) %>%
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment))+
  geom_col() +
  coord_flip() +
  labs(y = "Sentiment Score")
```

Word Cloud visualization of most recurring positive and negative words.

```{r}
library(reshape2)
library(wordcloud)
data %>%
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("red", "darkgreen"), max.words = 100)
```

